{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trabalho Final\n",
    "\n",
    "## Coleta Preparação e Análise de Dados\n",
    "\n",
    "#### Aléxia de Jesus Dorneles Pereira, Arthur Land Avila, Gustavo Giongo Lottermann, Matheus Gonzaga Krebs e Vicente Hofmeister"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trabalho feito utilizando [biblioteca Pysus](https://github.com/AlertaDengue/PySUS/tree/main). Caso necessário, confira a [documentação](https://pysus.readthedocs.io/en/latest/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pysus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from pysus.online_data import SINAN as SINAN_Online\n",
    "from pysus.online_data import SINASC as SINASC_Online\n",
    "from pysus.online_data import SIM as SIM_ONLINE\n",
    "from pysus.ftp.databases.sinan import SINAN\n",
    "from pysus.ftp.databases.sinasc import SINASC\n",
    "from pysus.ftp.databases.sim import SIM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import de bibliotecas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A sessão de código a seguir salva em listas os anos que os dados de sinan, sinasc e sim estão disponiveis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = ['AC', 'AL', 'AP', 'AM', 'BA', 'CE', 'DF', 'ES', 'GO', 'MA', 'MT', \\\n",
    "          'MS', 'MG', 'PA', 'PB', 'PR', 'PE', 'PI', 'RJ', 'RN', 'RS', 'RO', \\\n",
    "          'RR', 'SC', 'SP', 'SE', 'TO']\n",
    "\n",
    "sinan_years = SINAN_Online.get_available_years(\"DENG\")\n",
    "sinasc_years = SINASC_Online.get_available_years(group= 'DN', states = states)\n",
    "sim_years = SIM_ONLINE.get_available_years(group= 'CID10', states = states)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confere os anos em que todas bases de dados estão disponiveis simultaneamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avaliable_years = []\n",
    "\n",
    "for year in sinan_years:\n",
    "      if year in sinasc_years and year in sim_years:\n",
    "            avaliable_years.append(year)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SINAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "busca arquivos SINAN baseado nos anos definidos em years, descreve-os e realiza download dos datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = [2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022]\n",
    "sinan = SINAN().load()\n",
    "sinan_files = sinan.get_files(dis_code=['DENG'], year=years)\n",
    "\n",
    "parquet_path = os.getcwd() + \"/Data/Parquet/\"\n",
    "csv_path = os.getcwd() + '/Data/CSV/'\n",
    "\n",
    "if not 'Parquet' in os.listdir(os.getcwd() + \"/Data\") :\n",
    "      os.mkdir(parquet_path)\n",
    "\n",
    "if not 'CSV' in os.listdir(os.getcwd() + \"/Data\") :\n",
    "      os.mkdir(csv_path)\n",
    "\n",
    "for file in sinan_files:\n",
    "      if not file.basename.replace('.dbc', '.parquet') in os.listdir(parquet_path) and not file.basename.replace('.dbc', '.csv') in os.listdir(csv_path):\n",
    "            print(sinan.describe(file))\n",
    "            sinan.download(file, local_dir=parquet_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SINASC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = [2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022]\n",
    "sinasc = SINASC().load()\n",
    "sinasc_files = sinasc.get_files(group='DN', uf=states, year=years)\n",
    "\n",
    "parquet_path = os.getcwd() + \"/Data/Parquet/\"\n",
    "csv_path = os.getcwd() + '/Data/CSV/'\n",
    "\n",
    "if not 'Parquet' in os.listdir(os.getcwd() + \"/Data\") :\n",
    "      os.mkdir(parquet_path)\n",
    "\n",
    "if not 'CSV' in os.listdir(os.getcwd() + \"/Data\") :\n",
    "      os.mkdir(csv_path)\n",
    "\n",
    "for file in sinasc_files:\n",
    "      if not file.basename.replace('.dbc', '.parquet') in os.listdir(parquet_path) and not file.basename.replace('.dbc', '.csv') in os.listdir(csv_path):\n",
    "            print(sinasc.describe(file))\n",
    "            sinasc.download(file, local_dir=parquet_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = [2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022]\n",
    "sim = SIM().load()\n",
    "sim_files = sim.get_files('CID10', uf=states, year=years)\n",
    "\n",
    "parquet_path = os.getcwd() + \"/Data/Parquet/\"\n",
    "csv_path = os.getcwd() + '/Data/CSV/'\n",
    "\n",
    "if not 'Parquet' in os.listdir(os.getcwd() + \"/Data\") :\n",
    "      os.mkdir(parquet_path)\n",
    "\n",
    "if not 'CSV' in os.listdir(os.getcwd() + \"/Data\") :\n",
    "      os.mkdir(csv_path)\n",
    "\n",
    "for file in sim_files:\n",
    "      if not file.basename.replace('.dbc', '.parquet') in os.listdir(parquet_path) and not file.basename.replace('.dbc', '.csv') in os.listdir(csv_path):\n",
    "            print(sim.describe(file))\n",
    "            sim.download(file, local_dir=parquet_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transformação Parquet para CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transforma todos os .parquet em .csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_log_path = os.getcwd() + '/Data/error_log.txt'\n",
    "\n",
    "files_names = os.listdir(parquet_path)\n",
    "error_files = []\n",
    "\n",
    "for file in files_names:\n",
    "    try:\n",
    "        df = pd.read_parquet(path= parquet_path + file)\n",
    "        print(file)\n",
    "        df.to_csv(path_or_buf=(csv_path + file.replace('.parquet', '.csv')), sep=';')\n",
    "        \n",
    "        parquet_files = os.listdir(parquet_path + file)\n",
    "        for pFile in parquet_files:\n",
    "            os.remove(parquet_path + file + '/' + pFile)\n",
    "        os.rmdir(parquet_path + file) \n",
    "    except Exception as e:\n",
    "        error_files.append(file)\n",
    "        print(f\"Erro ao processar o arquivo: {file}\")\n",
    "\n",
    "        os.remove(path=parquet_path + file)\n",
    "\n",
    "\n",
    "\n",
    "# Escrever os arquivos que causaram erro em um arquivo de texto\n",
    "if len(error_files) > 0:\n",
    "    with open(error_log_path, 'w') as f:\n",
    "        for error_file in error_files:\n",
    "            f.write(f\"{error_file}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
