{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h2>Coleta, Preparação e Análise de Dados</h2>\n",
    "<h3>Prof. Luan Garcia</h3>    \n",
    "\n",
    "Material adaptado do notebook originalmente desenvolvido por: <a href=\"http://lattes.cnpq.br/2532893661927339\">Renato Moraes Silva</a>\n",
    "\n",
    " <hr style=\"height:2px\"> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introdução\n",
    "\n",
    "Frequentemente, a visualização dos dados auxilia na interpretação e na análise de como eles estão distribuídos. O Python possui algumas bibliotecas que facilitam o processo de visualização, tais como: `Pandas`, `Matplotlib` e `Seaborn`. \n",
    "\n",
    "Neste trabalho, utilizaremos a base de dados Iris [1] que está na pasta raiz deste exercício. É importante destacar que a base de dados Iris usada neste exercício foi modificada pelos autores por motivos didáticos [2]. A versão original dela pode ser encontrada no seguinte link: <https://archive.ics.uci.edu/ml/datasets/iris>. \n",
    "\n",
    "Usando a versão modificada dessa base de dados, os seguintes tópicos serão abordados:\n",
    "- eliminação de atributos irrelevantes \n",
    "- tratamento de valores faltantes \n",
    "- tratamento de valores redundantes ou inconsistentes\n",
    "- normalização dos dados\n",
    "- detecção e remoção de *outliers* \n",
    "- análise da distribuição das classes\n",
    "- correlação entre os atributos\n",
    "\n",
    "Para cada um destes tópicos, serão propostos exercícios ou serão apresentadas maneiras de como realizar a tarefa em questão.\n",
    "\n",
    "Seu trabalho é implementar o que é pedido nos exercícios abaixo e compreender o que está acontecendo ao longo do notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Recursos Necessários\n",
    "\n",
    "Para este *notebook*, deve ser utilizado o `Python 3.5` ou superior com as seguintes bibliotecas externas, que deverão ser instaladas (preferencialmente em um ambiente virtual conda):\n",
    "\n",
    "* [`matplotlib`](https://matplotlib.org/) (versão 3.1.3 ou superior): construção e exibição de gráficos variados\n",
    "* [`seaborn`](https://seaborn.pydata.org/) (versão 0.10.0 ou superior): construção e exibição de gráficos variados\n",
    "* [`numpy`](https://numpy.org) (versão 1.16.2 ou superior): manipulação de dados em formato de vetores e matrizes\n",
    "* [`pandas`](https://pandas.pydata.org/pandas-docs/stable/index.html) (versão 0.24.1 ou superior): manipulação de dados em formato de tabelas\n",
    "\n",
    "\n",
    "Será utilizado também o conjuntos de dados disponibilizado junto com este *notebook*, que se encontra no diretório `datasets`, em formato de arquivo `.csv`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Carregando os dados\n",
    "\n",
    "Primeiro, vamos importar todas as bibliotecas que serão utilizadas ao longo deste exercício."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import numpy as np # importa a biblioteca usada para trabalhar com vetores e matrizes\n",
    "import pandas as pd # importa a biblioteca usada para trabalhar com dataframes (dados em formato de tabela) e análise de dados\n",
    "\n",
    "# bibliotecas usadas para geracao de graficos\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em seguida, os dados serão carregados do arquivo para um DataFrame pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importa o arquivo e guarda em um dataframe do Pandas\n",
    "df_dataset = pd.read_csv( 'datasets/iris.csv', sep=',', index_col=None) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora, vamos dar uma olhada nas 10 primeiras amostras da base de dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exibe o dataframe\n",
    "df_dataset.head(n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A base de dados contém amostras de flores (linhas) representadas pelos seguintes atributos (colunas): `id_planta`, `comprimento_sepala`, `largura_sepala`, `comprimento_petala`, `largura_petala` e `cidade_origem`. Por fim, temos o atributo `classe` que contém a espécie de cada flor.\n",
    "\n",
    "O atributo `id_planta` é qualitativo, uma vez que é usado para identificar uma determinada amostra. Apesar dele possuir valores numéricos crescentes, ele exerce apenas a função de identificação e seus valores poderiam ser trocados por outros identificadores não numéricos sem nenhum prejuízo. O atributo `cidade_origem` também é qualitativo. Os atributos `comprimento_sepala`, `largura_sepala`, `comprimento_petala` e `largura_petala` são quantitativos contínuos.\n",
    "\n",
    "Quanto à escala, os atributos `id_planta` e `cidade_origem` são qualitativos nominais, enquanto os atributos `comprimento_sepala`, `largura_sepala`, `comprimento_petala` e `largura_petala` são quantitativos racionais.\n",
    "\n",
    "O atributo `classe` é qualitativo nominal e representa espécies de flores. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Atividades\n",
    "\n",
    "O nosso objetivo é preparar o dataset das flores Iris para uma tarefa de aprendizado de máquina (classificação). Caso não saiba o que é isto, não se preocupe, nosso objetivo é apenas preparar o dataset, não gerar algum tipo de modelo.\n",
    "\n",
    "O que desejamos no futuro é utilizar este dataset para identificar de forma automática a espécie de uma flor (`classe`), dados os demais atributos. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eliminação de atributos irrelevantes\n",
    "\n",
    "\n",
    "Não é preciso uma análise profunda para observar que os atributos `id_planta` e `cidade_origem` não contribuem para a identificação da classe. Portanto, como o dataset será utilizado para uma tarefa de aprendizado de máquina, podemos remover esses atributos, pois são irrelevantes. Em cenários reais, muitas vezes é necessário consultar especialistas para ajudar a identificar quais atributos são irrelevantes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercício\n",
    "\n",
    "1. Remova do dataset os atributos `id_planta` e `cidade_origem`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remova os atributos aqui"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tratamento de atributos com valores ausentes\n",
    "\n",
    "Outro passo importante, é verificar se existem atributos com valores ausentes (*NaN*) na base de dados. Começaremos analisando nosso dataset para verificar se existem valores faltantes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercício"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Armazene na variável `idxRowNan` abaixo os índices das linhas do dataset que possuem algum valor faltante.\n",
    "\n",
    "<b>Atenção</b>: Não necessariamente estarão faltando valores para todos atributos de uma linha."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idxRowNaN = #atualize a variável aqui"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com o comando abaixo podemos visualizar apenas os registros (linhas) que possuem valores faltantes. Como resultado esperado, devemos poder verificar que o atributo `largura_sepala` possui 2 amostras com valores ausentes e o atributo `comprimento_petala` possui 1 amostra com valor faltante. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dataset.iloc[idxRowNaN]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podemos ver todos os casos de valores faltantes ocorreram para instâncias da classe `Iris-setosa`. Este fato será relevante para nossa próxima tarefa.\n",
    "\n",
    "Existem diversas técnicas para tratar atributos faltantes. Como este problema possui poucos valores ausentes, vamos utilizar a média dos valores conhecidos da respectiva classe (`Iris-setosa`) para preencher nosso dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercício"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Substitua os valores faltantes da coluna `largura_sepala` com a média dos valores desta coluna para instâncias de `Iris-setosa`.\n",
    "\n",
    "4. Substitua os valores faltantes da coluna `comprimento_petala` com a média dos valores desta coluna para instâncias de `Iris-setosa`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#atualize os valores faltantes aqui"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se tudo ocorreu corretamente, abaixo será possível visualizar os registros que anteriormente possuíam valores faltantes preenchidos.\n",
    "Para a `largura_sepala` o valor esperado é aproximadamente $3.416$, já para `comprimento_petala`o valor esperado é aproximadamente $1.461$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dataset.loc[idxRowNaN]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tratamento de dados inconsistentes ou redundantes\n",
    "\n",
    "Outro passo importante, é verificar se existem dados inconsistentes ou redundantes. A forma mais comum de inconsistência é quando há amostras representadas por atributos com todos os valores iguais, mas com classes diferentes. A redundância é dada pela repetição de linhas na base de dados.\n",
    "\n",
    "A seguir, vamos verificar se existem amostras duplicadas (redundantes) e inconsistentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_duplicates = df_dataset[ df_dataset.duplicated(subset=['comprimento_sepala','largura_sepala','comprimento_petala','largura_petala'],keep=False)] \n",
    "\n",
    "# se houver valores redundantes ou inconsistentes, imprima \n",
    "if len(df_duplicates)>0:\n",
    "    print('\\nAmostras redundantes ou inconsistentes:')\n",
    "    display(df_duplicates)\n",
    "else:\n",
    "    print('Não existem valores duplicados')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podemos ver, existem algumas amostras redundantes (duplicadas) e outras inconsistentes (amostras iguais, mas com classes distintas). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercício\n",
    "5. Remova as instâncias redudantes e as instâncias inconsistentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#remova as instâncias redudantes / incosistentes aqui\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abaixo podemos verificar se ainda existem amostras redudantes ou incosistentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtém apenas as amostras onde os valores dos atributos estão duplicados\n",
    "df_duplicates = df_dataset[ df_dataset.duplicated(subset=['comprimento_sepala','largura_sepala','comprimento_petala','largura_petala'],keep=False)] \n",
    "\n",
    "# se tiver valores redundantes ou inconsistentes, imprime \n",
    "if len(df_duplicates)>0:\n",
    "    display(df_duplicates)\n",
    "else:\n",
    "    print('Não existem amostras redundantes ou inconsistentes')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalização dos atributos\n",
    "\n",
    "Agora, vamos gerar algumas estatísticas sobre a base de dados.\n",
    "\n",
    "A função `describe()` da biblioteca `Pandas` sumariza as principais estatísticas sobre os dados de um *data frame*, como a média, o desvio padrão, valor máximo, valor mínimo e alguns percentis.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apresenta as principais estatísticas da base de dados\n",
    "df_detalhes = df_dataset.describe()\n",
    "\n",
    "df_detalhes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Observe que a média do atributo `comprimento_sepala` é bastante superior a média do atributo `largura_petala`. Diante disso, está claro que a escala dos atributos é diferente, o que pode prejudicar alguns métodos de aprendizado de máquina."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercício\n",
    "6. Normalize os valores de todos atributos numéricos utilizando a técnica de normalização z-score (standardizaton)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalize o dataset aqui"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora que os dados estão normalizados, vamos analisar as informações estatísticas novamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apresenta as principais estatísticas da base de dados\n",
    "df_detalhes = df_dataset.describe()\n",
    "\n",
    "display(df_detalhes.round(8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver acima que a média (*mean*) ficou igual a 0 e o desvio padrão (*std*) igual a 1. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detecção de *outliers*\n",
    "\n",
    "Outro passo importante na análise e tratamento dos dados é a detecção de *outliers* (*i.e.*, dados gerados por leituras incorretas, erros de digitação, etc). \n",
    "\n",
    "Uma das maneiras mais simples de verificar se os dados contém *outliers* é criar um gráfico box plot de cada atributo. Para isso, podemos usar a função `boxplot` da biblioteca `Pandas`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gera um bloxplot para cada atributo\n",
    "df_dataset.boxplot(figsize=(15,7))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O box plot está indicando que os atributos `comprimento_sepala` e `largura_sepala` possuem *outliers*, o que pode prejudicar o desempenho de vários métodos de aprendizado de máquina, pois provavelmente tratam-se de amostras com valores de atributos incorretos. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outra forma de analisar se a base de dados contém *outliers* é usar gráficos de dispersão. Podemos plotar gráficos de dispersão a partir dos _dataframes_ utilizando a biblioteca `Seaborn`. Juntamente com essa biblioteca, também é recomendável importar a biblioteca `Matplotlib` para personalizar os gráficos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# matriz de gráficos scatter \n",
    "sns.pairplot(df_dataset, hue='classe', height=3.5)\n",
    "\n",
    "# mostra o gráfico usando a função show() da matplotlib\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observando os gráficos de dispersão, é fácil perceber que existem duas amostras da classe *Iris-virginica* que estão deslocadas no espaço em relação às demais amostras.\n",
    "\n",
    "Pelos gráficos, os *outliers* parecem ser mais visíveis na combinação dos atributos `comprimento_sepala` e `largura_sepala`. Então, vamos usar a função `lmplot` da biblioteca `Seaborn`para visualizar a combinação desses dois atributos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define o scatter plot\n",
    "sns.lmplot(x='comprimento_sepala', y='largura_sepala', data=df_dataset, \n",
    "           fit_reg=False,  \n",
    "           hue='classe')\n",
    "\n",
    "# cria um título para o gráfico\n",
    "plt.title('Comprimento vs largura da sepala')\n",
    "\n",
    "# mostra o gráfico\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pelos gráficos vistos até o momento, fica claro que um dos *outliers* possui um alto valor no atributo `largura_sepala`. Já o segundo outlier contém um alto valor no atributo `comprimento_sepala`. \n",
    "\n",
    "A bilioteca `Seaborn` permite criar gráficos boxplot agrupados por um determinado atributo, o que facilita a análise dos dados. No exemplo abaixo, criaremos boxplots para cada atributo agrupados pela classe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for atributo in df_dataset.columns[:-1]:\n",
    "    # define a dimensão do gráfico\n",
    "    plt.figure(figsize=(8,8))\n",
    "\n",
    "    # cria o boxplot\n",
    "    sns.boxplot(x=\"classe\", y=atributo, data=df_dataset, whis=1.5)\n",
    "\n",
    "    # mostra o gráfico\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os box plots dos atributos mostraram outros *outliers* que não haviam aparecido no primeiro box plot. Portanto, esses novos valores são considerados *outliers* se analisarmos as classes individualmente, mas não são considerados *outliers* se analisarmos a base de dados de forma geral. \n",
    "\n",
    "Outro tipo de gráfico que ajuda a detectar *outliers* é o histograma. Portanto, vamos usá-lo para analisar cada atributo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for atributo in df_dataset.columns[:-1]:\n",
    "    \n",
    "    # cria o histograma\n",
    "    n, bins, patches = plt.hist(df_dataset[atributo].values,bins=10, color='red', edgecolor='black', linewidth=0.9)\n",
    "\n",
    "    # cria um título para o gráfico\n",
    "    plt.title(atributo)\n",
    "\n",
    "    # mostra o gráfico\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nos histogramas, os *outliers* mais evidentes estão nos atributos `comprimento_sepala` e `largura_sepala`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uma das maneiras mais simples de tratar *outliers* é remover aqueles valores que são menores que $Q1 - 1.5 * IQR$ ou maiores que $Q3 + 1.5 * IQR$, onde $Q1$ é o primeiro quartil, $Q3$ é o terceiro quartil e $IQR$ é o intervalo interquartil. O IQR pode ser calculado pela seguinte equação: $IQR = Q3-Q1$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercício"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Remova as instâncias consideradas outliers do dataset. Vamos considerar como outliers valores que são menores que $Q1 - 1.5 * IQR$ ou maiores que $Q3 + 1.5 * IQR$. Utilize como base o IQR de cada atributo em relação a todos os valores na base de dados, em vez do IQR individual de cada classe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remova outliers aqui"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depois da remoção, se analizarmos o box plot e os gráficos de dispersão deveremos observar que não há mais nenhum *outlier* na base de dados. \n",
    "\n",
    "Abaixo vamos plotar os gráficos novamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apresenta as principais estatísticas sobre a base de dados\n",
    "df_dataset.boxplot(figsize=(15,7))\n",
    "plt.show()\n",
    "\n",
    "# matriz de gráficos scatter \n",
    "sns.pairplot(df_dataset, hue='classe', height=3.5)\n",
    "\n",
    "# mostra o gráfico usando a função show() da matplotlib\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com os novos gráficos de dispersão, também é possível perceber que a classe *Iris-setosa* é mais fácil de identificar, pois está mais separada no espaço de atributos. Por outro lado, em várias combinações de atributos, as classes *Iris-versicolor* e *Iris-virginica* se misturam."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**IMPORTANTE:** antes de realizar a remoção de *outliers*, é mandatório analisar cuidadosamente as características das amostras antes de removê-las. Em alguns casos, remover os *outliers* pode ser prejudicial. Além disso, algumas tarefas de aprendizado de máquina são voltadas para a detecção de *outliers* e, portanto, esses dados não podem ser removidos. Adicionalmente, se a base de dados for desbalanceada, a remoção dos *outliers* com base nas estatísticas de toda a base, pode acabar removendo amostras da classe minoritária (aquela que possui menos amostras). Ainda, alguns métodos de classificação, tais como métodos baseados em *ensemble* e métodos baseados em árvores, costumam ser robustos a *outliers*. Diante disso, em alguns problemas, é recomendável remover apenas aqueles *outliers* que são claramente erros de leitura/digitação, isto é, valores que estão fora dos limites aceitáveis para o que é esperado para um determinado atributo (por exemplo, uma pessoa com 500 anos ou um bebê com 300 kg). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Distribuição das classes\n",
    "\n",
    "Outro passo importante na análise de dados é verificar a distribuição das classes. Para isso, é possível criar um gráfico de barra indicando quantas amostras de cada classe há na base de dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( df_dataset['classe'].value_counts())\n",
    "\n",
    "# cria um gráfico de barras com a frequência de cada classe\n",
    "sns.countplot(x=\"classe\", data=df_dataset)\n",
    "\n",
    "# mostra o gráfico\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conforme podemos ver acima, as 3 classes possuem aproximadamente 50 instâncias cada uma, ou seja, temos um dataset balanceado. Se o número de exemplos em alguma das classes fosse muito superior às demais, teríamos que usar alguma técnica de balanceamento de classes, pois o modelo gerado pela maioira dos métodos de aprendizado supervisionado costuma ser tendencioso para as classes com maior número de amostras. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlação entre os atributos\n",
    "\n",
    "Quando dois atributos possuem valores idênticos ou muito semelhantes para todas as amostras, um deles deve ser eliminado ou eles devem ser combinados. Isso ajuda a diminuir o custo computacional das tarefas de aprendizado e evita que o aprendizado de alguns método seja prejudicado, principalmente os métodos baseados em otimização.\n",
    "\n",
    "Uma das maneiras mais comuns de analisar a correlação dos dados é através das matrizes de correlação e covariância. Podemos fazer isso usando as funções nativas de correlação e covariância da bilioteca `Pandas`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matriz de covariancia\n",
    "df_covariance = df_dataset[[\"comprimento_sepala\",\"comprimento_petala\",\n",
    "                            \"largura_sepala\", \"largura_petala\"]].cov()\n",
    "\n",
    "# matriz de correlação\n",
    "df_correlation = df_dataset[[\"comprimento_sepala\",\"comprimento_petala\",\n",
    "                            \"largura_sepala\", \"largura_petala\"]].corr()\n",
    "\n",
    "print('Matriz de covariância: ')\n",
    "display(df_covariance)\n",
    "\n",
    "print('\\n\\nMatriz de correlação: ')\n",
    "display(df_correlation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que os atributos `comprimento_petala` e `largura_petala` possuem alta covariância e alta correlação. Se o problema que estamos analisando tivesse muitos atributos, poderíamos pensar na possibilidade de combinar esses dois atributos. Se a correlação entre dois atributos for igual a 1 ou -1, significa que eles são redundantes e um deles poderia ser eliminado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "É importante notar que a alta correlação entre dois atributos não significa que um deles influencia no valor do outro. Veja alguns exemplos que mostram isso em <http://www.tylervigen.com/spurious-correlations>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Referências\n",
    "\n",
    "[1] R. A. Fisher. The use of multiple measurements in taxonomic problems. Annual Eugenics, 7, Part II, 179-188 (1936). DOI: [10.1111/j.1469-1809.1936.tb02137.x](http://dx.doi.org/10.1111/j.1469-1809.1936.tb02137.x).\n",
    "\n",
    "[2] Faceli, Katti, et al. Inteligência artificial: uma abordagem de aprendizado de máquina. (2021).\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prep",
   "language": "python",
   "name": "prep"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
