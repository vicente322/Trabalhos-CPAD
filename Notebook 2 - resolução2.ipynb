{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Buscando dados da internet</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Laboratório de Coletas, Preparação e Análise de Dados.</h3>\n",
    "Desenvolvendo um crawler básico.\n",
    "\n",
    "Prof. Luan Garcia\n",
    "\n",
    "Baseado no material de Richard Mitchel\n",
    "https://github.com/REMitchell/python-scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com a biblioteca Beautiful Soup vimos como é possível tratar documentos HTML como objetos no modelo DOM, buscando informação pelas *tags* e seus atributos. Porém, para chegarmos ao ponto de processar um documento HTML precisamos realizar o download do documento a partir do seu servidor web e como descobrir novos documentos a partir de um link de origem.\n",
    "\n",
    "Neste notebook, veremos como é possível fazer requisições HTTP utilizando a biblioteca urllib e como lidar com alguns problemas básicos que podem acontecer quando estamos trabalhando com um crawler.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primeiro passo é importar o módulo request da biblioteca urllib. Não é necessário instalar, pois é uma biblioteca nativa do Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para fazer o download do documento web, basta sabermos o endereço do documento e chamar o método read() do **urlopen**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para podermos tratar o documento utilizando a biblioteca BeautifulSoup podemos passar diretamente o documento carregado através da requisição HTTP e depois manipular conforme o necessário."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um problema bastante comum é o site que estamos tentando acessar não estar disponível, seja porque erramos o endereço, seja porque o servidor está fora do ar.\n",
    "\n",
    "Um solução simples é garantir que tenhamos um documento para tratar utilizando exceções."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O objetivo de um crawler é descobrir, a partir de um link raiz, outros documentos que estejam linkados de alguma forma.\n",
    "\n",
    "Uma maneira simples de realizar isto é filtrando pelas tags de links de um documento HTML. Com isto, encontramos todos os links dentro de um documento.\n",
    "\n",
    "Abaixo, um exemplo utilizando como raiz a página do ator Kevin Bacon na Wikipedia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evidentemente, nem todos links serão de nosso interesse. Podemos filtrar apenas os links que nos interessam procurando por algum padrão no endereço e utilizar uma expressão regular para realizar o filtro.\n",
    "\n",
    "Abaixo, vamos filtrar apenas links para outros artigos da wiki, ignorando âncoras, links para arquivos, etc. Faremos isso nos aproveitando de conhecimento de como um verbete na wiki é organizado. Todos links de artigos estarão sempre dentro da tag **div** que contém um atributo de **id** com valor **'bodyContent'**. Além disso, todo link de verbete necessariamente começa com o endereço \"/wiki/\" e não possui \":\" no endereço."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos generalizar este código em forma de uma função **getLinks()**. Isto possibilitará que busquemos os links de qualquer verbete da wiki."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A função **getLinks()** anterior funciona se quisermos encontrar todos os links de uma única página, porém, se quisermos fazer um crawler efetivo, precisamos procurar por páginas linkadas dentro de outras páginas de forma recursiva. Podemos fazer isso chamando a nosa própria função de procurar link de forma recursiva."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experimente executar o comando a seguir e veja o que acontece. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O que aconteceu? Será que isto é um problema? Se for, como podemos solucioná-lo?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def pega_autores(link):\n",
    "    url = \"https://www.imdb.com\"+link\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3\"\n",
    "    }\n",
    "\n",
    "\n",
    "    try:\n",
    "        response_serie = requests.get(url, headers=headers)  # Corrigindo a passagem da URL\n",
    "        response_serie.raise_for_status()\n",
    "    except requests.HTTPError as e:\n",
    "        print(\"The server returned an HTTP error:\", e)\n",
    "        return None\n",
    "    except requests.RequestException as e:\n",
    "        print(\"Request error:\", e)\n",
    "        return None\n",
    "    else:\n",
    "        html_serie = response_serie.text\n",
    "        soup = BeautifulSoup(html_serie, 'html.parser')\n",
    "        lista_div = soup.find('div', class_=\"ipc-chip-list__scroller\")\n",
    "        lista_span = lista_div.find_all('span', class_=\"ipc-chip__text\")\n",
    "        print(\"Generos: \")\n",
    "        for span in lista_span:\n",
    "            print(span.text)\n",
    "        list_atores = soup.find_all('a', class_=\"sc-bfec09a1-1 gCQkeh\")\n",
    "        print(\"Atores: \")\n",
    "        for ator in list_atores:\n",
    "           print(ator.text)\n",
    "        popularidade = soup.find('div', class_='sc-5f7fb5b4-1 fTREEx')\n",
    "        print(\"Popularidade:\", popularidade.text)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Breaking Bad\n",
      "62 eps\n",
      "2008\n",
      "9.5\n",
      "/title/tt0903747/?ref_=chttvtp_t_1\n",
      "Generos: \n",
      "Crime\n",
      "Drama\n",
      "Thriller\n",
      "Atores: \n",
      "Bryan Cranston\n",
      "Aaron Paul\n",
      "Anna Gunn\n",
      "Betsy Brandt\n",
      "RJ Mitte\n",
      "Dean Norris\n",
      "Bob Odenkirk\n",
      "Steven Michael Quezada\n",
      "Jonathan Banks\n",
      "Giancarlo Esposito\n",
      "Charles Baker\n",
      "Jesse Plemons\n",
      "Christopher Cousins\n",
      "Laura Fraser\n",
      "Matt Jones\n",
      "Michael Shamus Wiles\n",
      "Lavell Crawford\n",
      "Ray Campbell\n",
      "Popularidade: 28\n",
      "2. Planeta Terra II\n",
      "62 eps\n",
      "2016\n",
      "9.5\n",
      "/title/tt5491994/?ref_=chttvtp_t_2\n",
      "Generos: \n",
      "Documentary\n",
      "Atores: \n",
      "David Attenborough\n",
      "Chadden Hunter\n",
      "Michael J. Sanderson\n",
      "Ed Charles\n",
      "Sandesh Kadur\n",
      "Max Hug Williams\n",
      "Fredi Devas\n",
      "Elizabeth White\n",
      "Toby Nowlan\n",
      "Barrie Britton\n",
      "Gordon Buchanan\n",
      "Mark MacEwen\n",
      "Thomas Crowley\n",
      "Emma Brennand\n",
      "Pete McCowen\n",
      "Rob Drewett\n",
      "Jerome Poncet\n",
      "Emma Napper\n",
      "Popularidade: 1,399\n",
      "3. Planeta Terra\n",
      "62 eps\n",
      "2006\n",
      "9.4\n",
      "/title/tt0795176/?ref_=chttvtp_t_3\n",
      "Generos: \n",
      "Documentary\n",
      "Family\n",
      "Atores: \n",
      "Sigourney Weaver\n",
      "David Attenborough\n",
      "Nikolay Drozdov\n",
      "Thomas Anguti Johnston\n",
      "Sanae Ueda\n",
      "Huw Cordey\n",
      "Mark Linfield\n",
      "Doug Allan\n",
      "Chadden Hunter\n",
      "Justine Evans\n",
      "Paul Stewart\n",
      "Doug Anderson\n",
      "Jeff Wilson\n",
      "Michael Kelem\n",
      "Rick Rosenthal\n",
      "Simon King\n",
      "Tom Clarke\n",
      "Jonathan Keeling\n",
      "Popularidade: 2,179\n",
      "4. Irmãos de Guerra\n",
      "62 eps\n",
      "2001\n",
      "9.4\n",
      "/title/tt0185906/?ref_=chttvtp_t_4\n",
      "Generos: \n",
      "Drama\n",
      "History\n",
      "War\n",
      "Atores: \n",
      "Scott Grimes\n",
      "Damian Lewis\n",
      "Ron Livingston\n",
      "Shane Taylor\n",
      "Donnie Wahlberg\n",
      "Peter Youngblood Hills\n",
      "Matthew Leitch\n",
      "Nicholas Aaron\n",
      "Philip Barantini\n",
      "Michael Cudlitz\n",
      "Dexter Fletcher\n",
      "Rick Gomez\n",
      "James Madio\n",
      "Ross McCall\n",
      "Doug Allen\n",
      "George Calil\n",
      "Nolan Hemmings\n",
      "Robin Laing\n",
      "Popularidade: 67\n",
      "5. Chernobyl\n",
      "62 eps\n",
      "2019\n",
      "9.3\n",
      "/title/tt7366338/?ref_=chttvtp_t_5\n",
      "Generos: \n",
      "Drama\n",
      "History\n",
      "Thriller\n",
      "Atores: \n",
      "Jessie Buckley\n",
      "Jared Harris\n",
      "Stellan Skarsgård\n",
      "Adam Nagaitis\n",
      "Emily Watson\n",
      "Paul Ritter\n",
      "Robert Emms\n",
      "Sam Troughton\n",
      "Karl Davies\n",
      "Michael Socha\n",
      "Laura Elphinstone\n",
      "Jan Ricica\n",
      "Adrian Rawlins\n",
      "Alan Williams\n",
      "Con O'Neill\n",
      "Douggie McMeekin\n",
      "Nadia Clifford\n",
      "David Dencik\n",
      "Popularidade: 191\n",
      "6. A Escuta\n",
      "62 eps\n",
      "2002\n",
      "9.3\n",
      "/title/tt0306414/?ref_=chttvtp_t_6\n",
      "Generos: \n",
      "Crime\n",
      "Drama\n",
      "Thriller\n",
      "Atores: \n",
      "Dominic West\n",
      "Lance Reddick\n",
      "Sonja Sohn\n",
      "Wendell Pierce\n",
      "John Doman\n",
      "Deirdre Lovejoy\n",
      "Seth Gilliam\n",
      "Domenick Lombardozzi\n",
      "Clarke Peters\n",
      "Andre Royo\n",
      "Michael Kenneth Williams\n",
      "Jim True-Frost\n",
      "Frankie Faison\n",
      "Corey Parker Robinson\n",
      "Delaney Williams\n",
      "J.D. Williams\n",
      "Wood Harris\n",
      "Idris Elba\n",
      "Popularidade: 106\n",
      "7. Avatar: A Lenda de Aang\n",
      "62 eps\n",
      "2005\n",
      "9.3\n",
      "/title/tt0417299/?ref_=chttvtp_t_7\n",
      "Generos: \n",
      "Animation\n",
      "Action\n",
      "Adventure\n",
      "Atores: \n",
      "Dee Bradley Baker\n",
      "Zach Tyler Eisen\n",
      "Mae Whitman\n",
      "Jack De Sena\n",
      "Dante Basco\n",
      "Michaela Jill Murphy\n",
      "Mako\n",
      "Grey Griffin\n",
      "André Sogliuzzo\n",
      "Cricket Leigh\n",
      "Mark Hamill\n",
      "Jennie Kwan\n",
      "Olivia Hack\n",
      "Greg Baldwin\n",
      "Jim Meskimen\n",
      "James Garrett\n",
      "Jason Isaacs\n",
      "James Sie\n",
      "Popularidade: 42\n",
      "8. Planeta Azul II\n",
      "62 eps\n",
      "2017\n",
      "9.3\n",
      "/title/tt6769208/?ref_=chttvtp_t_8\n",
      "Generos: \n",
      "Documentary\n",
      "Atores: \n",
      "David Attenborough\n",
      "Peter Drost\n",
      "Roger Munns\n",
      "Roger Horrocks\n",
      "Popularidade: 4,409\n",
      "9. Família Soprano\n",
      "62 eps\n",
      "1999\n",
      "9.2\n",
      "/title/tt0141842/?ref_=chttvtp_t_9\n",
      "Generos: \n",
      "Crime\n",
      "Drama\n",
      "Atores: \n",
      "James Gandolfini\n",
      "Lorraine Bracco\n",
      "Edie Falco\n",
      "Michael Imperioli\n",
      "Steven Van Zandt\n",
      "Robert Iler\n",
      "Tony Sirico\n",
      "Jamie-Lynn Sigler\n",
      "Dominic Chianese\n",
      "Aida Turturro\n",
      "Steve Schirripa\n",
      "Drea de Matteo\n",
      "Dan Grimaldi\n",
      "Joseph R. Gannascoli\n",
      "Sharon Angela\n",
      "John Ventimiglia\n",
      "Vincent Curatola\n",
      "Frank Vincent\n",
      "Popularidade: 33\n",
      "10. Cosmos: Uma Odisseia do Espaço-Tempo\n",
      "62 eps\n",
      "2014\n",
      "9.3\n",
      "/title/tt2395695/?ref_=chttvtp_t_10\n",
      "Generos: \n",
      "Documentary\n",
      "Atores: \n",
      "Neil deGrasse Tyson\n",
      "Christopher Emerson\n",
      "Keythe Farley\n",
      "Piotr Michael\n",
      "Enn Reitel\n",
      "Stoney Emshwiller\n",
      "André Sogliuzzo\n",
      "Amanda Seyfried\n",
      "Kirsten Dunst\n",
      "Phil LaMarr\n",
      "Paul Sorvino\n",
      "Larry Cedar\n",
      "Christiane Amanpour\n",
      "Seth MacFarlane\n",
      "Fred Tatasciore\n",
      "Martin Jarvis\n",
      "Glenn Steinbaum\n",
      "Maria Frucci\n",
      "Popularidade: 1,604\n",
      "11. Cosmos\n",
      "62 eps\n",
      "1980\n",
      "9.3\n",
      "/title/tt0081846/?ref_=chttvtp_t_11\n",
      "Generos: \n",
      "Documentary\n",
      "Atores: \n",
      "Carl Sagan\n",
      "Jaromír Hanzlík\n",
      "Jonathan Fahn\n",
      "Jean Charney\n",
      "Cecilia White\n",
      "Bob Hevelone\n",
      "Bill Grant\n",
      "Linda Morabito\n",
      "Victor C. John\n",
      "Arthur 'Lonne' Lane\n",
      "Larry Soderblom\n",
      "Alan Belod\n",
      "Ronald A. Hilbert\n",
      "Dana Hlavácová\n",
      "Josef Vinklár\n",
      "Popularidade: 4,364\n",
      "12. Nosso Planeta\n",
      "62 eps\n",
      "2019\n",
      "9.3\n",
      "/title/tt9253866/?ref_=chttvtp_t_12\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 53\u001b[0m\n\u001b[0;32m     51\u001b[0m link \u001b[38;5;241m=\u001b[39m link_pagina_filme[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhref\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28mprint\u001b[39m(link)\n\u001b[1;32m---> 53\u001b[0m pega_autores(link)\n",
      "Cell \u001b[1;32mIn[24], line 12\u001b[0m, in \u001b[0;36mpega_autores\u001b[1;34m(link)\u001b[0m\n\u001b[0;32m      6\u001b[0m headers \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUser-Agent\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      8\u001b[0m }\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 12\u001b[0m     response_serie \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mget(url, headers\u001b[38;5;241m=\u001b[39mheaders)  \u001b[38;5;66;03m# Corrigindo a passagem da URL\u001b[39;00m\n\u001b[0;32m     13\u001b[0m     response_serie\u001b[38;5;241m.\u001b[39mraise_for_status()\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m requests\u001b[38;5;241m.\u001b[39mHTTPError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\mathe\\anaconda3\\envs\\AmbienteDesenvolvimento\\Lib\\site-packages\\requests\\api.py:73\u001b[0m, in \u001b[0;36mget\u001b[1;34m(url, params, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(url, params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     63\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \n\u001b[0;32m     65\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m request(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mget\u001b[39m\u001b[38;5;124m\"\u001b[39m, url, params\u001b[38;5;241m=\u001b[39mparams, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\mathe\\anaconda3\\envs\\AmbienteDesenvolvimento\\Lib\\site-packages\\requests\\api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[1;34m(method, url, **kwargs)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[1;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m session\u001b[38;5;241m.\u001b[39mrequest(method\u001b[38;5;241m=\u001b[39mmethod, url\u001b[38;5;241m=\u001b[39murl, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\mathe\\anaconda3\\envs\\AmbienteDesenvolvimento\\Lib\\site-packages\\requests\\sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[0;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[0;32m    587\u001b[0m }\n\u001b[0;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[1;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msend(prep, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39msend_kwargs)\n\u001b[0;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[1;32mc:\\Users\\mathe\\anaconda3\\envs\\AmbienteDesenvolvimento\\Lib\\site-packages\\requests\\sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[0;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[1;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m adapter\u001b[38;5;241m.\u001b[39msend(request, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[0;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[1;32mc:\\Users\\mathe\\anaconda3\\envs\\AmbienteDesenvolvimento\\Lib\\site-packages\\requests\\adapters.py:486\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    483\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m TimeoutSauce(connect\u001b[38;5;241m=\u001b[39mtimeout, read\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[0;32m    485\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 486\u001b[0m     resp \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39murlopen(\n\u001b[0;32m    487\u001b[0m         method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[0;32m    488\u001b[0m         url\u001b[38;5;241m=\u001b[39murl,\n\u001b[0;32m    489\u001b[0m         body\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mbody,\n\u001b[0;32m    490\u001b[0m         headers\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[0;32m    491\u001b[0m         redirect\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    492\u001b[0m         assert_same_host\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    493\u001b[0m         preload_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    494\u001b[0m         decode_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    495\u001b[0m         retries\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_retries,\n\u001b[0;32m    496\u001b[0m         timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[0;32m    497\u001b[0m         chunked\u001b[38;5;241m=\u001b[39mchunked,\n\u001b[0;32m    498\u001b[0m     )\n\u001b[0;32m    500\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    501\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "File \u001b[1;32mc:\\Users\\mathe\\anaconda3\\envs\\AmbienteDesenvolvimento\\Lib\\site-packages\\urllib3\\connectionpool.py:793\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[0;32m    790\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    792\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[1;32m--> 793\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_request(\n\u001b[0;32m    794\u001b[0m     conn,\n\u001b[0;32m    795\u001b[0m     method,\n\u001b[0;32m    796\u001b[0m     url,\n\u001b[0;32m    797\u001b[0m     timeout\u001b[38;5;241m=\u001b[39mtimeout_obj,\n\u001b[0;32m    798\u001b[0m     body\u001b[38;5;241m=\u001b[39mbody,\n\u001b[0;32m    799\u001b[0m     headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[0;32m    800\u001b[0m     chunked\u001b[38;5;241m=\u001b[39mchunked,\n\u001b[0;32m    801\u001b[0m     retries\u001b[38;5;241m=\u001b[39mretries,\n\u001b[0;32m    802\u001b[0m     response_conn\u001b[38;5;241m=\u001b[39mresponse_conn,\n\u001b[0;32m    803\u001b[0m     preload_content\u001b[38;5;241m=\u001b[39mpreload_content,\n\u001b[0;32m    804\u001b[0m     decode_content\u001b[38;5;241m=\u001b[39mdecode_content,\n\u001b[0;32m    805\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mresponse_kw,\n\u001b[0;32m    806\u001b[0m )\n\u001b[0;32m    808\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[0;32m    809\u001b[0m clean_exit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\mathe\\anaconda3\\envs\\AmbienteDesenvolvimento\\Lib\\site-packages\\urllib3\\connectionpool.py:537\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[0;32m    535\u001b[0m \u001b[38;5;66;03m# Receive the response from the server\u001b[39;00m\n\u001b[0;32m    536\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 537\u001b[0m     response \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39mgetresponse()\n\u001b[0;32m    538\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    539\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mread_timeout)\n",
      "File \u001b[1;32mc:\\Users\\mathe\\anaconda3\\envs\\AmbienteDesenvolvimento\\Lib\\site-packages\\urllib3\\connection.py:466\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    463\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mresponse\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HTTPResponse\n\u001b[0;32m    465\u001b[0m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[1;32m--> 466\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mgetresponse()\n\u001b[0;32m    468\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    469\u001b[0m     assert_header_parsing(httplib_response\u001b[38;5;241m.\u001b[39mmsg)\n",
      "File \u001b[1;32mc:\\Users\\mathe\\anaconda3\\envs\\AmbienteDesenvolvimento\\Lib\\http\\client.py:1423\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1421\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1422\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1423\u001b[0m         response\u001b[38;5;241m.\u001b[39mbegin()\n\u001b[0;32m   1424\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[0;32m   1425\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32mc:\\Users\\mathe\\anaconda3\\envs\\AmbienteDesenvolvimento\\Lib\\http\\client.py:331\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    329\u001b[0m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[0;32m    330\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 331\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_read_status()\n\u001b[0;32m    332\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n\u001b[0;32m    333\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\mathe\\anaconda3\\envs\\AmbienteDesenvolvimento\\Lib\\http\\client.py:292\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    291\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 292\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp\u001b[38;5;241m.\u001b[39mreadline(_MAXLINE \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    293\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n\u001b[0;32m    294\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus line\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\mathe\\anaconda3\\envs\\AmbienteDesenvolvimento\\Lib\\socket.py:707\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    705\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    706\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 707\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39mrecv_into(b)\n\u001b[0;32m    708\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[0;32m    709\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\mathe\\anaconda3\\envs\\AmbienteDesenvolvimento\\Lib\\ssl.py:1252\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[1;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[0;32m   1248\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1249\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1250\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m   1251\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[1;32m-> 1252\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mread(nbytes, buffer)\n\u001b[0;32m   1253\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1254\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[1;32mc:\\Users\\mathe\\anaconda3\\envs\\AmbienteDesenvolvimento\\Lib\\ssl.py:1104\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1102\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1103\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1104\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m, buffer)\n\u001b[0;32m   1105\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1106\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re   \n",
    "\n",
    "url = \"https://www.imdb.com/chart/toptv/?ref_=nv_tvv_250\"\n",
    "\n",
    "# Adicionando um cabeçalho de usuário\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3\"\n",
    "}\n",
    "\n",
    "try:\n",
    "    response = requests.get(url, headers=headers)\n",
    "    response.raise_for_status()\n",
    "except requests.HTTPError as e:\n",
    "    print(\"The server returned an HTTP error:\", e)\n",
    "except requests.RequestException as e:\n",
    "    print(\"Request error:\", e)\n",
    "else:\n",
    "    html = response.text\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    lista_series = soup.find('ul', class_=\"ipc-metadata-list ipc-metadata-list--dividers-between sc-a1e81754-0 eBRbsI compact-list-view ipc-metadata-list--base\")\n",
    "    if lista_series:\n",
    "        series = lista_series.find_all('li')\n",
    "        \n",
    "    for serie in series:\n",
    "        titulo_elemento = serie.find(class_= \"ipc-title__text\").text\n",
    "        print(titulo_elemento)\n",
    "        ano_estreia_elemento = serie.find(class_=\"sc-b0691f29-8 ilsLEX cli-title-metadata-item\").text\n",
    "        div = soup.find('div', class_=\"sc-b0691f29-7 hrgukm cli-title-metadata\")\n",
    "        spans = div.find_all('span', class_=\"sc-b0691f29-8 ilsLEX cli-title-metadata-item\")\n",
    "        \n",
    "        if len(spans)>= 2:\n",
    "            numero_episodios = spans[1].text\n",
    "            print(numero_episodios)\n",
    "            \n",
    "        rating = serie.find(class_= \"ipc-rating-star\").text\n",
    "        link_pagina_filme = serie.find(\"a\", class_= \"ipc-title-link-wrapper\")\n",
    "        re2_result = re.search(r'\\d{4}',ano_estreia_elemento)\n",
    "        \n",
    "        if re2_result:\n",
    "            ano_estreia_elemento = re.search(r'\\d{4}',ano_estreia_elemento).group(0)\n",
    "            print(ano_estreia_elemento)\n",
    "            \n",
    "        re_result = re.search(r'^\\d\\.\\d',rating) #aplicando a regex para extrair apenas o padrão 'digito ponto digito'\n",
    "        \n",
    "        if re_result:\n",
    "            rating = re.search(r'^\\d\\.\\d',rating).group(0) #string resultante da regex\n",
    "            print(rating)\n",
    "            \n",
    "        link = link_pagina_filme[\"href\"]\n",
    "        print(link)\n",
    "        pega_autores(link)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
